#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""é’ˆå¯¹ crop_weld_data ç›®å½•ç»“æ„çš„ç²¾ç®€æ•°æ®å¤„ç†æµæ°´çº¿."""

import os
import sys
import json
import argparse
import subprocess
from collections import OrderedDict
from pathlib import Path
from typing import Dict, List
import copy

import yaml

# ========================= è·¯å¾„é…ç½® =========================
SYSTEM = sys.platform
if os.name == "nt":
    raise EnvironmentError("å½“å‰è„šæœ¬ä»…é…ç½®äº†Linuxè·¯å¾„ï¼Œè¯·åœ¨Linuxç¯å¢ƒä¸‹ä½¿ç”¨")

DATA_ROOT = Path("/home/lenovo/code/CHT/datasets/Xray/opensource/SWRD8bit").resolve()
IMAGES_ROOT = DATA_ROOT / "crop_weld_images"
JSON_ROOT = DATA_ROOT / "crop_weld_jsons_merged"
OUTPUT_BASE_DIR = DATA_ROOT / "swr_pipeline"
REFERENCE_LABEL_MAP_PATH = Path(
    "/home/lenovo/code/CHT/datasets/Xray/self/1120/labeled/roi2_merge/yolo/dataset.yaml"
).resolve()
OUTPUT_CONFIG = {
    "yolo_dir": str(OUTPUT_BASE_DIR / "yolo"),
    "patch_dir": str(OUTPUT_BASE_DIR / "patch")
}

FIXED_PARAMS = {
    "labelme2yolo": {
        "seg": True,
        "unify_to_crack": False,
        "script_path": "convert/labelme2yolo.py"
    },
    "patchandenhance": {
        "overlap": 0.5,
        "enhance_mode": "windowing",
        "no_slice": True,
        "window_size": [640, 640],
        "label_mode": "seg",
        "script_path": "convert/pj/patchandenhance.py"
    }
}

PARAM_LOG_PATH = OUTPUT_BASE_DIR / "pipeline_params_SWRD.json"
PARAM_LOG: Dict = {
    "data_root": str(DATA_ROOT),
    "image_root": str(IMAGES_ROOT),
    "json_root": str(JSON_ROOT),
    "output_base_dir": str(OUTPUT_BASE_DIR),
    "datasets": [],
    "selected_steps": [],
    "commands": []
}

STEP_INFO = {
    "1": {"name": "Labelmeè½¬YOLO", "func": "step1_labelme2yolo", "output": "yolo_dir"},
    "2": {"name": "å›¾åƒè£å‰ªä¸å¢å¼º", "func": "step2_patch_enhance", "output": "patch_dir"}
}

DATASET_ENTRIES: List[Dict[str, str]] = []

# ========================= å·¥å…·å‡½æ•° =========================

def _ensure_log_dir():
    PARAM_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)

def save_param_log():
    _ensure_log_dir()
    with PARAM_LOG_PATH.open("w", encoding="utf-8") as f:
        json.dump(PARAM_LOG, f, ensure_ascii=False, indent=2)

def log_command(step_name: str, command: List[str], param_key: str = None,
                extra_info: Dict = None):
    arguments = command[2:] if len(command) > 2 else []
    params = {}
    if param_key and param_key in FIXED_PARAMS:
        params = copy.deepcopy(FIXED_PARAMS[param_key])
        params.pop("script_path", None)

    entry = {"step": step_name, "arguments": arguments}
    if params:
        entry["params"] = params
    if extra_info:
        entry["extra"] = extra_info

    PARAM_LOG["commands"].append(entry)
    save_param_log()

def run_command(command: List[str], step_name: str, param_key: str = None,
                extra_info: Dict = None):
    log_command(step_name, command, param_key, extra_info)
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Œ æ­£åœ¨æ‰§è¡Œã€{step_name}ã€‘")
    print(f"å‘½ä»¤ï¼š{' '.join(command)}")
    print(f"{'=' * 80}")

    try:
        subprocess.run(command, check=True, text=True)
        print(f"\nâœ… ã€{step_name}ã€‘æ‰§è¡ŒæˆåŠŸï¼")
    except subprocess.CalledProcessError as exc:
        print(f"\nâŒ ã€{step_name}ã€‘æ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯ç ï¼š{exc.returncode}")
        sys.exit(1)

def get_abs_path(relative_path: str) -> str:
    current_script_dir = Path(__file__).parent
    return str((current_script_dir / relative_path).resolve())

# ========================= æ•°æ®é›†æ‰«æä¸æ­¥éª¤ =========================

def discover_crop_weld_datasets(image_root: Path, json_root: Path) -> List[Dict[str, str]]:
    if not image_root.exists():
        raise FileNotFoundError(f"å›¾åƒæ ¹ç›®å½•ä¸å­˜åœ¨: {image_root}")
    if not json_root.exists():
        raise FileNotFoundError(f"æ ‡æ³¨æ ¹ç›®å½•ä¸å­˜åœ¨: {json_root}")

    datasets: List[Dict[str, str]] = []
    for orient_dir in sorted([p for p in image_root.iterdir() if p.is_dir()]):
        for subset_dir in sorted([p for p in orient_dir.iterdir() if p.is_dir()]):
            json_dir = json_root / orient_dir.name / subset_dir.name
            if not json_dir.exists():
                print(f"  âš ï¸ è·³è¿‡ {orient_dir.name}/{subset_dir.name}ï¼šç¼ºå°‘æ ‡æ³¨ {json_dir}")
                continue
            datasets.append({
                "name": f"{orient_dir.name}_{subset_dir.name}",
                "image_dir": str(subset_dir.resolve()),
                "json_dir": str(json_dir.resolve())
            })

    return datasets

def load_label_map_from_yaml(yaml_path: Path) -> OrderedDict:
    """è¯»å– dataset.yaml ä¸­çš„ label_id_map ç”Ÿæˆæœ‰åºæ ‡ç­¾æ˜ å°„"""
    if not yaml_path.exists():
        raise FileNotFoundError(f"å‚è€ƒ dataset.yaml ä¸å­˜åœ¨: {yaml_path}")

    try:
        with yaml_path.open("r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
    except yaml.YAMLError as err:
        raise RuntimeError(f"è§£æ {yaml_path} å¤±è´¥: {err}") from err

    label_map_raw = yaml_data.get("label_id_map") if yaml_data else None
    if not isinstance(label_map_raw, dict):
        raise ValueError(f"{yaml_path} ç¼ºå°‘æœ‰æ•ˆçš„ label_id_map")

    # ç¡®ä¿æŒ‰ç…§ç±»åˆ« ID æ’åºï¼Œé¿å… dict æ— åºå¯¼è‡´ç±»åˆ«é”™ä¹±
    ordered_pairs = sorted(label_map_raw.items(), key=lambda item: item[1])
    return OrderedDict(ordered_pairs)

def collect_all_labels(_datasets: List[Dict[str, str]], unify_to_crack: bool = False) -> OrderedDict:
    if unify_to_crack:
        print("\nğŸ“Š å¯ç”¨äº† unify_to_crackï¼Œæ‰€æœ‰æ ‡ç­¾ç»Ÿä¸€ä¸º 'crack'")
        label_map = OrderedDict([('crack', 0)])
        print(f"ğŸ“‹ æ ‡ç­¾æ˜ å°„ï¼š{dict(label_map)}")
        return label_map

    print("\nğŸ“Š è¯»å–å‚è€ƒæ•°æ®é›†æ ‡ç­¾æ˜ å°„...")
    label_map = load_label_map_from_yaml(REFERENCE_LABEL_MAP_PATH)
    print(f"ğŸ“‹ å¼•ç”¨ {REFERENCE_LABEL_MAP_PATH} ä¸­çš„ label_id_mapï¼š")
    for label, idx in label_map.items():
        print(f"  {idx}: {label}")

    return label_map

def process_labelme2yolo_unified(datasets: List[Dict[str, str]], output_dir: str):
    unify_to_crack = FIXED_PARAMS["labelme2yolo"].get("unify_to_crack", False)
    label_map = collect_all_labels(datasets, unify_to_crack)
    if not label_map:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾")
        sys.exit(1)

    script_path = get_abs_path(FIXED_PARAMS["labelme2yolo"]["script_path"])
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    for dataset in datasets:
        image_dir = dataset["image_dir"]
        json_dir = dataset["json_dir"]
        if not os.path.exists(image_dir) or not os.path.exists(json_dir):
            print(f"âš ï¸ è·³è¿‡ {dataset['name']}ï¼šè·¯å¾„ä¸å­˜åœ¨")
            continue

        print(f"\nå¤„ç†æ•°æ®é›†: {dataset['name']}")
        command = [
            sys.executable, script_path,
            "--json_dir", json_dir,
            "--image_dir", image_dir,
            "--output_dir", output_dir,
            "--label_map", json.dumps(dict(label_map))
        ]
        if FIXED_PARAMS["labelme2yolo"].get("seg"):
            command.append("--seg")

        run_command(command, f"Labelmeè½¬YOLO - {dataset['name']}",
                    param_key="labelme2yolo", extra_info=dataset)

def process_patch_enhance(input_dir: str, output_dir: str):
    script_path = get_abs_path(FIXED_PARAMS["patchandenhance"]["script_path"])
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    command = [
        sys.executable, script_path,
        "--input_dir", input_dir,
        "--output_dir", output_dir,
        "--overlap", str(FIXED_PARAMS["patchandenhance"]["overlap"]),
        "--enhance_mode", FIXED_PARAMS["patchandenhance"]["enhance_mode"],
        "--window_size",
        str(FIXED_PARAMS["patchandenhance"]["window_size"][0]),
        str(FIXED_PARAMS["patchandenhance"]["window_size"][1]),
        "--label_mode", FIXED_PARAMS["patchandenhance"]["label_mode"]
    ]
    if FIXED_PARAMS["patchandenhance"].get("no_slice"):
        command.append("--no_slice")

    run_command(command, "å›¾åƒè£å‰ªä¸å¢å¼º", param_key="patchandenhance")

# ========================= CLI ä¸æ­¥éª¤æ§åˆ¶ =========================

def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="SWRD æ•°æ®å¤„ç†æµæ°´çº¿ï¼šLabelmeâ†’YOLOâ†’è£å‰ªå¢å¼º",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  python %(prog)s --steps 12   # è¿è¡Œå…¨éƒ¨ä¸¤æ­¥
  python %(prog)s --steps 1    # ä»…è½¬æ¢Labelme
  python %(prog)s --steps 2    # ä»…è£å‰ªå¢å¼ºï¼ˆéœ€å…ˆå®Œæˆæ­¥éª¤1ï¼‰
        """
    )
    parser.add_argument('--steps', type=str, default='12',
                        help='éœ€è¦æ‰§è¡Œçš„æ­¥éª¤ç¼–å·ç»„åˆ (é»˜è®¤: 12)')
    parser.add_argument('--force', action='store_true',
                        help='å¼ºåˆ¶ç»§ç»­æ‰§è¡Œï¼Œå³ä½¿æ£€æµ‹åˆ°ç¼ºå°‘è¾“å…¥ç›®å½•')
    return parser.parse_args()

def validate_steps(steps_str: str) -> List[str]:
    valid_steps = set(STEP_INFO.keys())
    steps: List[str] = []
    for char in steps_str:
        if char in valid_steps and char not in steps:
            steps.append(char)
        elif char not in valid_steps:
            print(f"âš ï¸ å¿½ç•¥æ— æ•ˆæ­¥éª¤ç¼–å· '{char}'")
    if not steps:
        raise ValueError("æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ­¥éª¤")
    return steps

def step1_labelme2yolo():
    if not DATASET_ENTRIES:
        raise RuntimeError("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®é›†ï¼Œæ— æ³•æ‰§è¡Œæ­¥éª¤1")
    process_labelme2yolo_unified(DATASET_ENTRIES, OUTPUT_CONFIG["yolo_dir"])

def step2_patch_enhance():
    input_dir = OUTPUT_CONFIG["yolo_dir"]
    if not os.path.exists(input_dir):
        print(f"âš ï¸ è­¦å‘Šï¼šYOLOè¾“å‡ºç›®å½•ä¸å­˜åœ¨ {input_dir}ï¼Œè¯·å…ˆè¿è¡Œæ­¥éª¤1")
    process_patch_enhance(input_dir, OUTPUT_CONFIG["patch_dir"])

# ========================= ä¸»å…¥å£ =========================

def main():
    args = parse_arguments()
    try:
        steps = validate_steps(args.steps)
    except ValueError as err:
        print(f"âŒ {err}")
        sys.exit(1)

    datasets = discover_crop_weld_datasets(IMAGES_ROOT, JSON_ROOT)
    if not datasets:
        print("âŒ æœªåœ¨ crop_weld_images ä¸­å‘ç°æœ‰æ•ˆå­ç›®å½•ï¼Œè¯·æ£€æŸ¥æ•°æ®ç»„ç»‡æ–¹å¼")
        sys.exit(1)

    global DATASET_ENTRIES
    DATASET_ENTRIES = datasets
    PARAM_LOG["datasets"] = [d["name"] for d in datasets]
    PARAM_LOG["selected_steps"] = steps
    save_param_log()

    print("ğŸš€ SWRD æ•°æ®å¤„ç†æµæ°´çº¿å¯åŠ¨ï¼")
    print(f"å›¾åƒæ ¹ç›®å½•ï¼š{IMAGES_ROOT}")
    print(f"æ ‡æ³¨æ ¹ç›®å½•ï¼š{JSON_ROOT}")
    print(f"è¾“å‡ºæ ¹ç›®å½•ï¼š{OUTPUT_BASE_DIR}")
    print(f"å¾…æ‰§è¡Œæ­¥éª¤ï¼š{' '.join(steps)}")
    for step in steps:
        print(f"  {step}: {STEP_INFO[step]['name']}")

    print("\n" + "=" * 80)
    print("å¼€å§‹æ‰§è¡Œé€‰å®šæ­¥éª¤")
    print("=" * 80)

    for step in steps:
        func_name = STEP_INFO[step]['func']
        func = globals()[func_name]
        try:
            func()
        except Exception as exc:
            print(f"\nâŒ æ­¥éª¤{step}æ‰§è¡Œå¤±è´¥ï¼š{exc}")
            if args.force:
                print("ä½¿ç”¨ --forceï¼Œç»§ç»­åç»­æ­¥éª¤")
                continue
            sys.exit(1)

    print("\n" + "ğŸ‰" * 10)
    print("æ‰€æœ‰é€‰å®šæ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
    for step in steps:
        output_key = STEP_INFO[step].get('output')
        if output_key:
            print(f"  æ­¥éª¤{step}è¾“å‡ºç›®å½•ï¼š{OUTPUT_CONFIG[output_key]}")
    print("ğŸ‰" * 10)

if __name__ == "__main__":
    main()
