#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import subprocess
import sys
import json
from typing import List, Dict
from collections import OrderedDict
from pathlib import Path
import platform
from tqdm import tqdm
import shutil
import argparse
import copy
import yaml

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
DEFAULT_CONFIG_PATH = os.path.join(CURRENT_DIR, "configs", "pipeline_profiles.yaml")

CONFIG_PATH = DEFAULT_CONFIG_PATH
ACTIVE_PROFILE_NAME = None
BASE_PATH = ""
JSON_BASE_PATH = ""
OUTPUT_BASE_DIR = ""
REFERENCE_LABEL_MAP_PATH = "/datasets/PAR/Xray/self/1120/labeled/roi2_merge/yolo/dataset.yaml"
DATASETS: List[str] = []
OUTPUT_CONFIG: Dict[str, str] = {}
FIXED_PARAMS: Dict[str, Dict] = {}
PARAM_LOG_PATH = ""
PARAM_LOG: Dict = {}

def _ensure_log_dir():
    if not PARAM_LOG_PATH:
        return
    os.makedirs(os.path.dirname(PARAM_LOG_PATH), exist_ok=True)

def save_param_log():
    """æŒä¹…åŒ–æµæ°´çº¿å‚æ•°è®°å½•"""
    if not PARAM_LOG_PATH:
        return
    _ensure_log_dir()
    with open(PARAM_LOG_PATH, 'w', encoding='utf-8') as f:
        json.dump(PARAM_LOG, f, ensure_ascii=False, indent=2)

def log_command(step_name: str, command: List[str], param_key: str = None,
                extra_info: Dict = None):
    """è®°å½•è„šæœ¬è°ƒç”¨åŠå…¶è¾“å…¥å‚æ•°"""
    arguments = command[2:] if len(command) > 2 else []
    params = {}
    if param_key and param_key in FIXED_PARAMS:
        params = copy.deepcopy(FIXED_PARAMS[param_key])
        params.pop("script_path", None)

    entry = {
        "step": step_name,
        "arguments": arguments,
    }

    if params:
        entry["params"] = params

    if extra_info:
        entry["extra"] = extra_info

    PARAM_LOG["commands"].append(entry)
    save_param_log()

# å®šä¹‰æ­¥éª¤ä¿¡æ¯
STEP_INFO = {
    '1': {
        'name': 'Labelmeè½¬YOLO',
        'func': 'step1_labelme2yolo',
        'input': None,
        'output': 'yolo_dir'
    },
    '2': {
        'name': 'YOLO ROIæå–',
        'func': 'step2_roi_extractor',
        'input': 'yolo_dir',
        'output': 'roi_dir'
    },
    '3': {
        'name': 'YOLOç«–å›¾æ—‹è½¬',
        'func': 'step3_rotate_yolo',
        'input': 'roi_dir',
        'output': 'roi_rotate'
    },
    '4': {
        'name': 'å›¾åƒè£å‰ªä¸å¢å¼º',
        'func': 'step4_patch_enhance',
        'input': 'roi_rotate',
        'output': 'patch_dir'
    },
    '5': {
        'name': 'è®­ç»ƒä»»åŠ¡è½¬æ¢',
        'func': 'step5_seg2det',
        'input': 'patch_dir',
        'output': 'cls_dir'
    },
    '6': {
        'name': 'YOLOè½¬COCO',
        'func': 'step6_yolo2coco',
        'input': 'cls_dir',
        'output': 'coco_dir'
    },
    '7': {
        'name': 'COCOæ•°æ®é›†åˆå¹¶',
        'func': 'step7_merge_coco',
        'input': 'coco_dir',
        'output': 'merged_coco_dir'
    }
}

def resolve_path(path_value: str, base_dir: str = None) -> str:
    """å°†è·¯å¾„è§£æä¸ºç»å¯¹è·¯å¾„ï¼Œå¿…è¦æ—¶ç›¸å¯¹ base_dir."""
    if path_value is None:
        return None

    expanded = os.path.expanduser(str(path_value))
    if os.path.isabs(expanded):
        return os.path.abspath(expanded)

    if base_dir:
        return os.path.abspath(os.path.join(base_dir, expanded))

    return os.path.abspath(expanded)


def load_pipeline_profile(config_path: str, requested_profile: str = None) -> str:
    """è¯»å–é…ç½®æ–‡ä»¶å¹¶åº”ç”¨æŒ‡å®š profile."""
    config_path = resolve_path(config_path or DEFAULT_CONFIG_PATH)
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{config_path}")

    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f) or {}

    if not isinstance(config_data, dict):
        raise ValueError("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›ä¸ºå­—å…¸ç»“æ„")

    profiles = config_data.get("profiles")
    if not isinstance(profiles, dict) or not profiles:
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘ profiles å®šä¹‰")

    profile_name = requested_profile or config_data.get("default_profile")
    if not profile_name:
        current_platform = platform.system()
        for name, profile_data in profiles.items():
            if profile_data.get("platform") == current_platform:
                profile_name = name
                break

    if not profile_name:
        profile_name = next(iter(profiles.keys()))

    if profile_name not in profiles:
        raise KeyError(f"é…ç½®æ–‡ä»¶ä¸­ä¸å­˜åœ¨ profile: {profile_name}")

    apply_profile(config_path, profile_name, profiles[profile_name])
    return profile_name


def apply_profile(config_path: str, profile_name: str, profile_data: Dict):
    """æ ¹æ® profile è®¾ç½®å…¨å±€è·¯å¾„å’Œå‚æ•°."""
    global CONFIG_PATH, ACTIVE_PROFILE_NAME, BASE_PATH, JSON_BASE_PATH
    global OUTPUT_BASE_DIR, DATASETS, OUTPUT_CONFIG, FIXED_PARAMS
    global PARAM_LOG_PATH, PARAM_LOG
    global REFERENCE_LABEL_MAP_PATH

    paths_section = profile_data.get("paths") or {}
    base_path_raw = paths_section.get("base_path")
    if not base_path_raw:
        raise ValueError(f"profile {profile_name} ç¼ºå°‘ paths.base_path")
    json_base_raw = paths_section.get("json_base_path")
    if not json_base_raw:
        raise ValueError(f"profile {profile_name} ç¼ºå°‘ paths.json_base_path")

    output_base_raw = paths_section.get("output_base_dir") or "pipeline_outputs"
    labelme_params = (profile_data.get("params") or {}).get("labelme2yolo", {})
    reference_label_map_raw = paths_section.get("reference_label_map_path")
    if not reference_label_map_raw and not labelme_params.get("unify_to_crack"):
        raise ValueError(f"profile {profile_name} ç¼ºå°‘ paths.reference_label_map_path")

    CONFIG_PATH = config_path
    ACTIVE_PROFILE_NAME = profile_name
    BASE_PATH = resolve_path(base_path_raw)
    JSON_BASE_PATH = resolve_path(json_base_raw)
    OUTPUT_BASE_DIR = resolve_path(output_base_raw, BASE_PATH)
    REFERENCE_LABEL_MAP_PATH = resolve_path(reference_label_map_raw, BASE_PATH) if reference_label_map_raw else ""

    datasets = profile_data.get("datasets") or []
    if not isinstance(datasets, list):
        raise ValueError(f"profile {profile_name} çš„ datasets å¿…é¡»æ˜¯åˆ—è¡¨")
    DATASETS = list(datasets)

    outputs_section = profile_data.get("outputs") or {}
    if not isinstance(outputs_section, dict) or not outputs_section:
        raise ValueError(f"profile {profile_name} ç¼ºå°‘ outputs å®šä¹‰")
    resolved_outputs: Dict[str, str] = {}
    for key, value in outputs_section.items():
        if value is None:
            raise ValueError(f"profile {profile_name} ä¸­ outputs.{key} ä¸ºç©º")
        resolved_outputs[key] = resolve_path(value, OUTPUT_BASE_DIR)
    OUTPUT_CONFIG = resolved_outputs

    FIXED_PARAMS = copy.deepcopy(profile_data.get("params") or {})

    param_log_raw = profile_data.get("param_log_path")
    PARAM_LOG_PATH = resolve_path(param_log_raw, OUTPUT_BASE_DIR) if param_log_raw else os.path.join(OUTPUT_BASE_DIR, "pipeline_params.json")

    required_outputs = {info["output"] for info in STEP_INFO.values() if info.get("output")}
    missing_outputs = sorted(key for key in required_outputs if key not in OUTPUT_CONFIG)
    if missing_outputs:
        raise ValueError(f"profile {profile_name} ç¼ºå°‘ä»¥ä¸‹è¾“å‡ºç›®å½•é…ç½®ï¼š{', '.join(missing_outputs)}")

    PARAM_LOG = {
        "config_path": CONFIG_PATH,
        "config_profile": ACTIVE_PROFILE_NAME,
        "base_path": BASE_PATH,
        "json_base_path": JSON_BASE_PATH,
        "reference_label_map_path": REFERENCE_LABEL_MAP_PATH,
        "datasets": list(DATASETS),
        "output_base_dir": OUTPUT_BASE_DIR,
        "selected_steps": [],
        "commands": []
    }

# ===========================================================================

def load_label_map_from_yaml(yaml_path: str) -> OrderedDict:
    """ä» dataset.yaml è¯»å– label_id_mapã€‚"""
    if not yaml_path:
        raise ValueError("ç¼ºå°‘å‚è€ƒ dataset.yaml è·¯å¾„")

    yaml_file = Path(yaml_path)
    if not yaml_file.exists():
        raise FileNotFoundError(f"å‚è€ƒ dataset.yaml ä¸å­˜åœ¨: {yaml_file}")

    try:
        with yaml_file.open("r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
    except yaml.YAMLError as err:
        raise RuntimeError(f"è§£æ {yaml_file} å¤±è´¥: {err}") from err

    label_map_raw = yaml_data.get("label_id_map") if yaml_data else None
    if not isinstance(label_map_raw, dict):
        raise ValueError(f"{yaml_file} ç¼ºå°‘æœ‰æ•ˆçš„ label_id_map")

    ordered_pairs = sorted(label_map_raw.items(), key=lambda item: item[1])
    return OrderedDict(ordered_pairs)

# ===========================================================================

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ•°æ®å¤„ç†æµæ°´çº¿æ§åˆ¶è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  python %(prog)s --steps 1234567  # è¿è¡Œæ‰€æœ‰7ä¸ªæ­¥éª¤
  python %(prog)s --steps 1234     # åªè¿è¡Œå‰4ä¸ªæ­¥éª¤
  python %(prog)s --steps 2345     # åªè¿è¡Œæ­¥éª¤2ã€3ã€4ã€5
  python %(prog)s --steps 135      # åªè¿è¡Œæ­¥éª¤1ã€3ã€5
  python %(prog)s --steps 6        # åªè¿è¡ŒYOLOâ†’COCO
  
æ­¥éª¤è¯´æ˜ï¼š
  1: Labelmeè½¬YOLOæ ¼å¼
  2: YOLO ROIåŒºåŸŸæå–
  3: YOLOç«–å›¾æ—‹è½¬
  4: å›¾åƒè£å‰ªä¸å¢å¼º
  5: è®­ç»ƒä»»åŠ¡è½¬æ¢ï¼ˆsegè½¬det/clsï¼‰
  6: YOLOâ†’COCO è½¬æ¢
  7: COCO æ•°æ®é›†åˆå¹¶
        """
    )
    
    parser.add_argument(
        '--steps',
        type=str,
        default='1234567',
        help='è¦æ‰§è¡Œçš„æ­¥éª¤ç¼–å·ï¼Œå¦‚ "1234567" æ‰§è¡Œå…¨éƒ¨ï¼Œ"1234" æ‰§è¡Œå‰å››æ­¥ (é»˜è®¤: 1234567)'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶æ‰§è¡Œæ­¥éª¤ï¼Œå³ä½¿å‰ç½®ä¾èµ–çš„è¾“å‡ºç›®å½•ä¸å­˜åœ¨'
    )

    parser.add_argument(
        '--config-path',
        type=str,
        default=DEFAULT_CONFIG_PATH,
        help=f'é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {DEFAULT_CONFIG_PATH})'
    )

    parser.add_argument(
        '--profile',
        type=str,
        default=None,
        help='é…ç½®æ–‡ä»¶ä¸­è¦ä½¿ç”¨çš„ profile åç§°ï¼ˆé»˜è®¤ä½¿ç”¨ default_profile æˆ–æ“ä½œç³»ç»ŸåŒ¹é…é¡¹ï¼‰'
    )

    return parser.parse_args()

def validate_steps(steps_str: str) -> List[str]:
    """éªŒè¯å¹¶è¿”å›è¦æ‰§è¡Œçš„æ­¥éª¤åˆ—è¡¨"""
    valid_steps = set('1234567')
    steps = []
    
    for char in steps_str:
        if char in valid_steps:
            if char not in steps:  # é¿å…é‡å¤
                steps.append(char)
        else:
            print(f"âš ï¸ è­¦å‘Šï¼šå¿½ç•¥æ— æ•ˆçš„æ­¥éª¤ç¼–å· '{char}'")
    
    if not steps:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æœ‰æ•ˆçš„æ­¥éª¤å¯æ‰§è¡Œï¼")
        sys.exit(1)
    
    return steps

def collect_all_labels(datasets: List[str], json_base_path: str,
                       unify_to_crack: bool = False,
                       reference_label_map_path: str = None) -> OrderedDict:
    """
    æ”¶é›†æ‰€æœ‰æ•°æ®é›†çš„æ ‡ç­¾ï¼Œå»ºç«‹ç»Ÿä¸€çš„æ ‡ç­¾æ˜ å°„
    """
    # å¦‚æœå¯ç”¨äº†unify_to_crackï¼Œç›´æ¥è¿”å›crackæ˜ å°„
    if unify_to_crack:
        print("\nğŸ“Š å¯ç”¨äº† unify_to_crackï¼Œæ‰€æœ‰æ ‡ç­¾å°†ç»Ÿä¸€ä¸º 'crack'")
        label_map = OrderedDict([('crack', 0)])
        print(f"ğŸ“‹ ç»Ÿä¸€æ ‡ç­¾æ˜ å°„ï¼š{dict(label_map)}")
        return label_map

    if reference_label_map_path:
        print("\nğŸ“Š ä»å‚è€ƒ dataset.yaml è¯»å–æ ‡ç­¾æ˜ å°„...")
        label_map = load_label_map_from_yaml(reference_label_map_path)
        print(f"ğŸ“‹ å¼•ç”¨ {reference_label_map_path} ä¸­çš„ label_id_mapï¼š")
        for label, idx in label_map.items():
            print(f"  {idx}: {label}")
        return label_map

    print("\nğŸ“Š æ”¶é›†æ‰€æœ‰æ•°æ®é›†çš„æ ‡ç­¾...")
    all_labels = set()
    dataset_labels = {}

    for dataset in datasets:
        json_dir = os.path.join(json_base_path, dataset, "label")
        if not os.path.exists(json_dir):
            print(f"  âš ï¸ è·³è¿‡ {dataset}ï¼šæ ‡æ³¨ç›®å½•ä¸å­˜åœ¨ {json_dir}")
            continue

        dataset_labels[dataset] = set()

        # æ‰«æè¯¥æ•°æ®é›†çš„æ‰€æœ‰JSONæ–‡ä»¶
        for json_file in os.listdir(json_dir):
            if not json_file.endswith('.json'):
                continue

            json_path = os.path.join(json_dir, json_file)
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                for shape in data.get('shapes', []):
                    label = shape.get('label', '').strip()
                    if label:
                        dataset_labels[dataset].add(label)
                        all_labels.add(label)

            except Exception as e:
                print(f"  âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {json_file}: {e}")

        if dataset_labels[dataset]:
            print(f"  âœ“ {dataset}: å‘ç° {len(dataset_labels[dataset])} ä¸ªæ ‡ç­¾")

    # åˆ›å»ºç»Ÿä¸€çš„æ ‡ç­¾æ˜ å°„
    sorted_labels = sorted(all_labels)
    label_map = OrderedDict([(label, idx) for idx, label in enumerate(sorted_labels)])

    print(f"\nğŸ“‹ ç»Ÿä¸€æ ‡ç­¾æ˜ å°„ï¼ˆå…± {len(label_map)} ä¸ªæ ‡ç­¾ï¼‰ï¼š")
    for label, idx in label_map.items():
        # æ‰¾å‡ºå“ªäº›æ•°æ®é›†åŒ…å«è¿™ä¸ªæ ‡ç­¾
        datasets_with_label = [d for d, labels in dataset_labels.items() if label in labels]
        print(f"  {idx}: {label} (å‡ºç°åœ¨: {', '.join(datasets_with_label)})")

    return label_map

def create_dataset_yaml(output_dir: str, label_map: OrderedDict):
    """åˆ›å»ºç»Ÿä¸€çš„dataset.yamlæ–‡ä»¶"""
    yaml_path = os.path.join(output_dir, "dataset.yaml")

    content = f"""# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# ç»Ÿä¸€æ•°æ®é›†é…ç½®æ–‡ä»¶

# æ•°æ®é›†è·¯å¾„
path: {output_dir}  # dataset root dir
train: images/train  # train images (relative to 'path')
val: images/val  # val images (relative to 'path')

# ç±»åˆ«
nc: {len(label_map)}  # number of classes
names: {list(label_map.keys())}  # class names

# æ ‡ç­¾IDæ˜ å°„
label_id_map: {dict(label_map)}
"""

    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"\nâœ… åˆ›å»ºç»Ÿä¸€çš„ dataset.yaml: {yaml_path}")

def process_labelme2yolo_unified(datasets: List[str], base_path: str,
                                  json_base_path: str, output_dir: str,
                                  ):
    """
    ç›´æ¥å¤„ç†æ‰€æœ‰æ•°æ®é›†åˆ°ä¸»ç›®å½•ï¼Œä½¿ç”¨ç»Ÿä¸€çš„æ ‡ç­¾æ˜ å°„
    """

    # è·å– unify_to_crack è®¾ç½®
    unify_to_crack = FIXED_PARAMS["labelme2yolo"].get("unify_to_crack", False)
    if unify_to_crack:
        print("\nâš ï¸ æ³¨æ„ï¼šå·²å¯ç”¨ unify_to_crackï¼Œæ‰€æœ‰æ ‡ç­¾å°†è¢«ç»Ÿä¸€ä¸º 'crack'")

    # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰æ ‡ç­¾ï¼Œå»ºç«‹ç»Ÿä¸€æ˜ å°„
    label_map = collect_all_labels(
        datasets,
        json_base_path,
        unify_to_crack,
        REFERENCE_LABEL_MAP_PATH
    )

    if not label_map:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾ï¼")
        sys.exit(1)

    # ç¬¬äºŒæ­¥ï¼šç›´æ¥å¤„ç†æ‰€æœ‰æ•°æ®é›†åˆ°ä¸»ç›®å½•
    script_path = get_abs_path(FIXED_PARAMS["labelme2yolo"]["script_path"])

    for dataset in datasets:
        image_dir = os.path.join(base_path, dataset)
        json_dir = os.path.join(json_base_path, dataset, "label")

        if not os.path.exists(image_dir) or not os.path.exists(json_dir):
            print(f"âš ï¸ è·³è¿‡ {dataset}ï¼šè·¯å¾„ä¸å­˜åœ¨")
            continue

        print(f"\nå¤„ç†æ•°æ®é›†: {dataset}")

        command = [
            sys.executable, script_path,
            "--json_dir", json_dir,
            "--image_dir", image_dir,
            "--output_dir", output_dir,
            "--label_map", json.dumps(dict(label_map))  # ä¼ é€’ç»Ÿä¸€çš„æ ‡ç­¾æ˜ å°„
        ]

        if FIXED_PARAMS["labelme2yolo"]["seg"]:
            command.append("--seg")

        # æ‰§è¡Œè½¬æ¢
        run_command(
            command,
            f"Labelmeè½¬YOLO - {dataset}",
            param_key="labelme2yolo",
            extra_info={"dataset": dataset}
        )

def run_command(command: List[str], step_name: str, param_key: str = None,
                extra_info: Dict = None):
    """æ‰§è¡Œå‘½ä»¤"""
    log_command(step_name, command, param_key, extra_info)
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Œ æ­£åœ¨æ‰§è¡Œã€{step_name}ã€‘")
    print(f"å‘½ä»¤ï¼š{' '.join(command)}")
    print(f"{'=' * 80}")

    try:
        subprocess.run(
            command,
            check=True,
            stdout=None,
            stderr=None,
            text=True,
            env=os.environ
        )
        print(f"\nâœ… ã€{step_name}ã€‘æ‰§è¡ŒæˆåŠŸï¼")
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ ã€{step_name}ã€‘æ‰§è¡Œå¤±è´¥ï¼é”™è¯¯ç ï¼š{e.returncode}")
        sys.exit(1)

def get_abs_path(relative_path: str) -> str:
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„"""
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.abspath(os.path.join(current_script_dir, relative_path))

def process_roi_extractor(input_dir: str, output_dir: str):
    """æ‰§è¡Œ ROI æå–"""
    script_path = get_abs_path(FIXED_PARAMS["yolo_roi_extractor"]["script_path"])
    command = [
        sys.executable, script_path,
        "--input_dir", input_dir,
        "--output_dir", output_dir,
        "--model_path", FIXED_PARAMS["yolo_roi_extractor"]["model_path"],
        "--roi_conf", str(FIXED_PARAMS["yolo_roi_extractor"]["roi_conf"]),
        "--roi_iou", str(FIXED_PARAMS["yolo_roi_extractor"]["roi_iou"]),
        "--padding", str(FIXED_PARAMS["yolo_roi_extractor"]["padding"]),
        "--mode", FIXED_PARAMS["yolo_roi_extractor"]["mode"]
    ]

    run_command(command, "YOLO ROIæå–", param_key="yolo_roi_extractor")

def process_rotate_yolo(input_dir: str, output_dir: str):
    """æ‰§è¡ŒYOLOç«–å›¾æ—‹è½¬æ ‡å‡†åŒ–"""
    script_path = get_abs_path(FIXED_PARAMS["rotate_yolo"]["script_path"])
    command = [
        sys.executable, script_path,
        "--input", input_dir,
        "--output", output_dir
    ]

    run_command(command, "YOLOç«–å›¾æ—‹è½¬", param_key="rotate_yolo")

def process_patch_enhance(input_dir: str, output_dir: str):
    """æ‰§è¡Œå›¾åƒè£å‰ªå¢å¼º"""
    script_path = get_abs_path(FIXED_PARAMS["patchandenhance"]["script_path"])
    patch_cfg = FIXED_PARAMS["patchandenhance"]
    slice_mode = patch_cfg.get("slice_mode")
    if slice_mode is None:
        slice_mode = 1 if patch_cfg.get("no_slice") else 2

    command = [
        sys.executable, script_path,
        "--input_dir", input_dir,
        "--output_dir", output_dir,
        "--enhance_mode", patch_cfg["enhance_mode"],
        "--label_mode", patch_cfg["label_mode"]
    ]

    if slice_mode == 2:
        command.extend([
            "--overlap", str(patch_cfg["overlap"]),
            "--window_size",
            str(patch_cfg["window_size"][0]),
            str(patch_cfg["window_size"][1])
        ])

    command.extend(["--slice_mode", str(slice_mode)])

    run_command(command, "å›¾åƒè£å‰ªä¸å¢å¼º", param_key="patchandenhance")

def seg2det(input_dir: str, output_dir: str):
    """æ‰§è¡Œè®­ç»ƒä»»åŠ¡è½¬æ¢"""
    seg_cfg = FIXED_PARAMS["seg2det"]
    script_path = get_abs_path(seg_cfg["script_path"])
    command = [
        sys.executable, script_path,
        "--input_dir", input_dir,
        "--output_dir", output_dir,
        "--mode", str(seg_cfg["mode"]),
    ]
    if seg_cfg.get("balance_data"):
        command.append("--balance_data")
        balance_ratio = seg_cfg.get("balance_ratio")
        if balance_ratio is not None:
            command.extend(["--balance_ratio", str(balance_ratio)])

    run_command(command, "è®­ç»ƒä»»åŠ¡è½¬æ¢", param_key="seg2det")


def process_yolo2coco(input_dir: str, output_dir: str):
    """æ‰§è¡Œ YOLOâ†’COCO è½¬æ¢"""
    yolo2coco_cfg = FIXED_PARAMS.get("yolo2coco")
    if not yolo2coco_cfg:
        raise KeyError("é…ç½®ç¼ºå°‘ params.yolo2coco")

    script_path = get_abs_path(yolo2coco_cfg["script_path"])
    command = [
        sys.executable, script_path,
        "--input_dir", input_dir,
        "--output_dir", output_dir
    ]

    task = yolo2coco_cfg.get("task")
    if task:
        command.extend(["--task", str(task)])
    if yolo2coco_cfg.get("test_split_ratio") is not None:
        command.extend(["--test_split_ratio", str(yolo2coco_cfg["test_split_ratio"])])
    if yolo2coco_cfg.get("split_seed") is not None:
        command.extend(["--split_seed", str(yolo2coco_cfg["split_seed"])])

    run_command(command, "YOLOè½¬COCO", param_key="yolo2coco")


def process_merge_coco(dataset_a_dir: str, output_dir: str):
    """æ‰§è¡Œ COCO æ•°æ®é›†åˆå¹¶"""
    merge_cfg = FIXED_PARAMS.get("merge_coco")
    if not merge_cfg:
        raise KeyError("é…ç½®ç¼ºå°‘ params.merge_coco")

    dataset_b_raw = merge_cfg.get("dataset_b")
    if not dataset_b_raw:
        raise ValueError("merge_coco.dataset_b æœªé…ç½®ï¼Œè¯·åœ¨ YAML ä¸­æŒ‡å®š")

    dataset_b_path = resolve_path(dataset_b_raw, BASE_PATH)
    script_path = get_abs_path(merge_cfg["script_path"])
    command = [
        sys.executable, script_path,
        "--dataset-a", dataset_a_dir,
        "--dataset-b", dataset_b_path,
        "--output-dir", output_dir
    ]

    splits = merge_cfg.get("splits")
    if splits:
        command.extend(["--splits"] + [str(split) for split in splits])

    if merge_cfg.get("prefix_a"):
        command.extend(["--prefix-a", str(merge_cfg["prefix_a"])])
    if merge_cfg.get("prefix_b"):
        command.extend(["--prefix-b", str(merge_cfg["prefix_b"])])
    if merge_cfg.get("copy_images"):
        command.append("--copy-images")

    merge_ratio_config = merge_cfg.get("merge_ratio")
    logged_merge_ratio = None
    if isinstance(merge_ratio_config, (list, tuple)):
        ratio_values = [str(value) for value in merge_ratio_config if value is not None]
        if ratio_values:
            command.extend(["--merge-ratio"] + ratio_values)
            logged_merge_ratio = list(merge_ratio_config)
    elif merge_ratio_config is not None:
        command.extend(["--merge-ratio", str(merge_ratio_config)])
        logged_merge_ratio = merge_ratio_config

    run_command(
        command,
        "åˆå¹¶COCOæ•°æ®é›†",
        param_key="merge_coco",
        extra_info={
            "dataset_b": str(dataset_b_path),
            "merge_ratio": logged_merge_ratio if logged_merge_ratio is not None else "default"
        }
    )

# =================== æ­¥éª¤æ‰§è¡Œå‡½æ•° ===================

def step1_labelme2yolo():
    """æ­¥éª¤1: Labelmeè½¬YOLOæ ¼å¼"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤1: æ‰¹é‡å¤„ç† Labelme æ•°æ®ï¼ˆä½¿ç”¨ç»Ÿä¸€æ ‡ç­¾æ˜ å°„ï¼‰")
    print("=" * 100)
    
    process_labelme2yolo_unified(
        DATASETS,
        BASE_PATH,
        JSON_BASE_PATH,
        OUTPUT_CONFIG["yolo_dir"],
    )

def step2_roi_extractor():
    """æ­¥éª¤2: YOLO ROIæå–"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤2: æ‰§è¡Œ YOLO ROI åŒºåŸŸæå–")
    print("=" * 100)
    
    if not os.path.exists(OUTPUT_CONFIG["yolo_dir"]):
        print(f"âš ï¸ è­¦å‘Šï¼šYOLO æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨ {OUTPUT_CONFIG['yolo_dir']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤1")
    
    process_roi_extractor(OUTPUT_CONFIG["yolo_dir"], OUTPUT_CONFIG["roi_dir"])

def step3_rotate_yolo():
    """æ­¥éª¤3: YOLOç«–å›¾æ—‹è½¬"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤3: æ‰§è¡Œç«–å›¾æ—‹è½¬å½’ä¸€")
    print("=" * 100)
    
    if not os.path.exists(OUTPUT_CONFIG["roi_dir"]):
        print(f"âš ï¸ è­¦å‘Šï¼šROI æå–ç›®å½•ä¸å­˜åœ¨ {OUTPUT_CONFIG['roi_dir']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤2")
    
    process_rotate_yolo(OUTPUT_CONFIG["roi_dir"], OUTPUT_CONFIG["roi_rotate"])

def step4_patch_enhance():
    """æ­¥éª¤4: å›¾åƒè£å‰ªä¸å¢å¼º"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤4: æ‰§è¡Œå›¾åƒè£å‰ªä¸å¢å¼º")
    print("=" * 100)
    
    if not os.path.exists(OUTPUT_CONFIG["roi_rotate"]):
        print(f"âš ï¸ è­¦å‘Šï¼šROI æ—‹è½¬ç›®å½•ä¸å­˜åœ¨ {OUTPUT_CONFIG['roi_rotate']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤3")
    
    process_patch_enhance(OUTPUT_CONFIG["roi_rotate"], OUTPUT_CONFIG["patch_dir"])

def step5_seg2det():
    """æ­¥éª¤5: è®­ç»ƒä»»åŠ¡è½¬æ¢"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤5: æ‰§è¡Œè®­ç»ƒä»»åŠ¡è½¬æ¢")
    print("=" * 100)
    
    if not os.path.exists(OUTPUT_CONFIG["patch_dir"]):
        print(f"âš ï¸ è­¦å‘Šï¼špatch ç›®å½•ä¸å­˜åœ¨ {OUTPUT_CONFIG['patch_dir']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤4")
    
    seg2det(OUTPUT_CONFIG["patch_dir"], OUTPUT_CONFIG["cls_dir"])


def step6_yolo2coco():
    """æ­¥éª¤6: YOLOâ†’COCO è½¬æ¢"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤6: YOLOâ†’COCO è½¬æ¢")
    print("=" * 100)

    if not os.path.exists(OUTPUT_CONFIG["cls_dir"]):
        print(f"âš ï¸ è­¦å‘Šï¼šdet æ•°æ®ç›®å½•ä¸å­˜åœ¨ {OUTPUT_CONFIG['cls_dir']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤5")

    process_yolo2coco(OUTPUT_CONFIG["cls_dir"], OUTPUT_CONFIG["coco_dir"])


def step7_merge_coco():
    """æ­¥éª¤7: åˆå¹¶ COCO æ•°æ®é›†"""
    print("\n" + "=" * 100)
    print("ğŸ“ æ­¥éª¤7: åˆå¹¶ COCO æ•°æ®é›†")
    print("=" * 100)

    if not os.path.exists(OUTPUT_CONFIG["coco_dir"]):
        print(f"âš ï¸ è­¦å‘Šï¼šCOCO è½¬æ¢è¾“å‡ºä¸å­˜åœ¨ {OUTPUT_CONFIG['coco_dir']}")
        print("  æç¤ºï¼šå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤6")

    process_merge_coco(OUTPUT_CONFIG["coco_dir"], OUTPUT_CONFIG["merged_coco_dir"])

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    try:
        active_profile = load_pipeline_profile(args.config_path, args.profile)
    except Exception as exc:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥ï¼š{exc}")
        sys.exit(1)
    
    print("ğŸš€ æ•°æ®å¤„ç†æµæ°´çº¿å¯åŠ¨ï¼ˆå¯æ§ç‰ˆæœ¬ï¼‰ï¼")
    print(f"é…ç½®æ–‡ä»¶ï¼š{CONFIG_PATH}")
    print(f"ä½¿ç”¨çš„profileï¼š{active_profile}")
    print(f"åŸºç¡€è·¯å¾„ï¼š{BASE_PATH}")
    print(f"å¾…å¤„ç†æ•°æ®é›†ï¼š{DATASETS}")
    
    # éªŒè¯æ­¥éª¤
    steps = validate_steps(args.steps)
    PARAM_LOG["selected_steps"] = list(steps)
    save_param_log()
    
    print(f"\nğŸ“Œ å°†è¦æ‰§è¡Œçš„æ­¥éª¤ï¼š{' '.join(steps)}")
    for step in steps:
        print(f"  {step}: {STEP_INFO[step]['name']}")
    
    
    print("\n" + "=" * 100)
    print("å¼€å§‹æ‰§è¡Œé€‰å®šçš„æ­¥éª¤")
    print("=" * 100)
    
    # æ‰§è¡Œé€‰å®šçš„æ­¥éª¤
    for step in steps:
        step_func_name = STEP_INFO[step]['func']
        step_func = globals()[step_func_name]
        
        try:
            step_func()
        except Exception as e:
            print(f"\nâŒ æ­¥éª¤{step}æ‰§è¡Œå¤±è´¥ï¼š{e}")
            if not args.force:
                print("ç»ˆæ­¢æ‰§è¡Œï¼ˆä½¿ç”¨ --force å¯ä»¥ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤ï¼‰")
                sys.exit(1)
            else:
                print("ä½¿ç”¨äº† --force å‚æ•°ï¼Œç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")
    
    # å®Œæˆä¿¡æ¯
    print("\n" + "ğŸ‰" * 50)
    print("ğŸ‰ æ‰€é€‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
    print(f"ğŸ“ æ‰§è¡Œçš„æ­¥éª¤ï¼š{' '.join(steps)}")
    
    # æ˜¾ç¤ºå„æ­¥éª¤çš„è¾“å‡ºç›®å½•
    for step in steps:
        output_key = STEP_INFO[step]['output']
        if output_key:
            output_dir = OUTPUT_CONFIG[output_key]
            print(f"  æ­¥éª¤{step}è¾“å‡ºï¼š{output_dir}")
    
    print("ğŸ‰" * 50)

if __name__ == "__main__":
    main()
